{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "from random import sample\n",
    "from statistics import mean\n",
    "\n",
    "# import statsmodels.stats.api as sms\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DEFINITIONS\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    '''\n",
    "    Function to get confidence interval of list of data\n",
    "    '''\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m-h, m+h\n",
    "\n",
    "#Decided against using datetime, so just wrote some custom functions for the int type yyyymm\n",
    "def monthminus(i):\n",
    "    '''\n",
    "    get the previous month\n",
    "    '''\n",
    "    if(i == 192606):\n",
    "        return i\n",
    "    elif(i%100 == 1):\n",
    "        year = i//100\n",
    "        return (year-1)*100 + 12\n",
    "    else:\n",
    "        return i-1   \n",
    "\n",
    "\n",
    "def monthdifference(dob, curr):\n",
    "    '''\n",
    "    get difference in months between two dates\n",
    "    '''\n",
    "    ydob = dob//100\n",
    "    ycur = curr//100\n",
    "    mdob = dob%100\n",
    "    mcur = curr%100\n",
    "    return (ycur-ydob)*12 + mcur-mdob\n",
    "\n",
    "\n",
    "starty = 1926  \n",
    "startm = 7\n",
    "endy = 2016\n",
    "N = 100\n",
    "startd = starty*100 + startm  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADING\n",
    "data = pd.read_csv('./newdata2.csv') #data only containing relevant share codes\n",
    "fulldata = pd.read_csv('./fulldata2.csv') #data containing all share codes (to accomodate reclassification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "Implementing a dataframe matrix, with indices as PERMNO's, and columns as dates to quickly access key stock variables without having to parse through entire database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING - limited sharecodes\n",
    "\n",
    "fulldata = fulldata[~fulldata.SHRCD.isna()]\n",
    "\n",
    "codereplace = [500,520,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,580,584]\n",
    "retcodereplace = ['A','S','T','P']\n",
    "data.loc[data['DLSTCD'].isin(codereplace) & data['DLRET'].isin(retcodereplace), 'DLRET' ] = -0.3\n",
    "data.loc[data['DLRET'].isin(retcodereplace), 'DLRET'] = -.9999\n",
    "\n",
    "\n",
    "\n",
    "data['RET'] = data['RET'].fillna(0.00)\n",
    "data['RETX'] = data['RETX'].fillna(0.00)\n",
    "data['DLRET'] = data['DLRET'].fillna(0.00)\n",
    "data.loc[data['RET'].isin(['A','B','C','D','E']), 'RET'] = 0.00\n",
    "data.loc[data['RETX'].isin(['A','B','C','D','E']), 'RETX'] = 0.00\n",
    "# data = data.loc[~data['RET'].isin(['B','C'])]\n",
    "data = data.drop_duplicates(subset=['PERMNO','date','RET'], keep = 'first')\n",
    "\n",
    "\n",
    "data['date'] = data['date']//100  #only care about monthly returns\n",
    "# data['date'] = pd.to_datetime(data['date'], format=\"%Y%m\")\n",
    "# data['date']\n",
    "    \n",
    "#ADDING IN DOB\n",
    "dateofbirths = data.sort_values(by = 'date').drop_duplicates(subset = ['PERMNO'],keep='first')\n",
    "dateofbirths = dateofbirths.rename(columns={'date':'dateofbirth'})\n",
    "data = data.merge(dateofbirths[['PERMNO','dateofbirth']], on = 'PERMNO', how = 'left')\n",
    "\n",
    "#adding in Date of Delisting    \n",
    "delistings = data.loc[~data['DLSTCD'].isna()]\n",
    "delistings=  delistings.rename(columns = {'date':'dateofdelisting'})\n",
    "data = data.merge(delistings[['PERMNO','dateofdelisting']], on = 'PERMNO', how = 'left')\n",
    "\n",
    "\n",
    "#delete rows  that are useless delisting returns\n",
    "indexNames = list(data[data['PRC'].isna() & data['SHROUT'].isna() & (data['dateofdelisting']<data['date'])].index)\n",
    "data.drop(indexNames, inplace = True)\n",
    "\n",
    "\n",
    "#get Age by month\n",
    "data['Age'] = (monthdifference(data['dateofbirth'],data['date'])+1)\n",
    "#get Size\n",
    "data['Size'] = data['SHROUT'] * abs(data['PRC'])\n",
    "\n",
    "data['Size'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "data['RET'] = data['RET'].apply(pd.to_numeric)\n",
    "data['RETX'] = data['RETX'].apply(pd.to_numeric)\n",
    "\n",
    "data['DLRET'] = data['DLRET'].apply(pd.to_numeric)\n",
    "\n",
    "ret_max1 = data[['date','RET','PERMNO']]\n",
    "\n",
    "ret_max = ret_max1.pivot(index = 'PERMNO', columns = 'date', values = 'RET')  #matrix of returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Size'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7fb551881704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprice_max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfulldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PRC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PERMNO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# div_max1 = fulldata[['date','DIVAMT','PERMNO']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0msize_max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfulldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Size'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PERMNO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mfull_ret_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret_max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PERMNO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'RET'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Size'] not in index\""
     ]
    }
   ],
   "source": [
    "#DATA PREPROCESSING - all sharecodes\n",
    "\n",
    "\n",
    "listofPERMNO = data.PERMNO.unique()\n",
    "\n",
    "#filter full data so that only PERMNOs that were at one time 10,11, or 12\n",
    "fulldata = fulldata.loc[fulldata['PERMNO'].isin(listofPERMNO)]\n",
    "fulldata['date'] = fulldata['date']//100\n",
    "\n",
    "\n",
    "fulldata.loc[fulldata['DLSTCD'].isin(codereplace) & fulldata['DLRET'].isin(retcodereplace), 'DLRET' ] = -0.3\n",
    "fulldata.loc[fulldata['DLRET'].isin(retcodereplace), 'DLRET'] = -.9999\n",
    "# fulldata.loc[~fulldaDLSTCDta['DLRET'].isna(), 'DLRET'] = -.9999\n",
    "fulldata['RET'] = fulldata['RET'].fillna(0.00)\n",
    "fulldata['RETX'] = fulldata['RETX'].fillna(0.00)\n",
    "fulldata['DLRET'] = fulldata['DLRET'].fillna(0.00)\n",
    "fulldata.loc[fulldata['RET'].isin(['A','B','C','D','E']), 'RET'] = 0.00\n",
    "fulldata.loc[fulldata['RETX'].isin(['A','B','C','D','E']), 'RETX'] = 0.00\n",
    "# fulldata = fulldata.loc[~data['RET'].isin(['B','C'])]\n",
    "fulldata = fulldata.drop_duplicates(subset=['PERMNO','date','RET'], keep = 'first')\n",
    "\n",
    "\n",
    "#ADDING IN DOB\n",
    "dateofbirths = fulldata.sort_values(by = 'date').drop_duplicates(subset = ['PERMNO'],keep='first')\n",
    "dateofbirths = dateofbirths.rename(columns={'date':'dateofbirth'})\n",
    "fulldata = fulldata.merge(dateofbirths[['PERMNO','dateofbirth']], on = 'PERMNO', how = 'left')\n",
    "\n",
    "#adding in Date of Delisting    \n",
    "delistings = fulldata.loc[~fulldata['DLSTCD'].isna()]\n",
    "delistings=  delistings.rename(columns = {'date':'dateofdelisting'})\n",
    "fulldata = fulldata.merge(delistings[['PERMNO','dateofdelisting']], on = 'PERMNO', how = 'left')\n",
    "\n",
    "#delete useless delisting returns\n",
    "# print(fulldata['dateofdelisting'])\n",
    "indexNames = list(fulldata[fulldata['PRC'].isna() & (fulldata['dateofdelisting']<fulldata['date'])].index)\n",
    "fulldata.drop(indexNames, inplace = True)\n",
    "\n",
    "#indexNames = list(fulldata[fulldata['PRC'].isna() & fulldata['dateofdelisting'].isna()].index)\n",
    "indexNames = list(fulldata[fulldata['date']< 192606].index)\n",
    "\n",
    "fulldata.drop(indexNames, inplace = True)\n",
    "\n",
    "\n",
    "fulldata.loc[fulldata.dateofbirth < 192606, 'dateofbirth'] = 192606\n",
    "\n",
    "fulldata['Age'] = (monthdifference(fulldata['dateofbirth'],fulldata['date'])+1)\n",
    "\n",
    "fulldata['RET'] = fulldata['RET'].apply(pd.to_numeric)\n",
    "fulldata['RETX'] = fulldata['RETX'].apply(pd.to_numeric)\n",
    "fulldata['DLRET'] = fulldata['DLRET'].apply(pd.to_numeric)\n",
    "\n",
    "ret_max1 = fulldata[['date','RET','PERMNO']]\n",
    "ret_max2 = fulldata[['date','RETX','PERMNO']]\n",
    "dlret_max1 = fulldata[['date','DLRET','PERMNO']]\n",
    "age_max1 = fulldata[['date','Age','PERMNO']]\n",
    "price_max1 = fulldata[['date', 'PRC','PERMNO']]\n",
    "# div_max1 = fulldata[['date','DIVAMT','PERMNO']]\n",
    "size_max1 = fulldata[['date','Size','PERMNO']]\n",
    "\n",
    "full_ret_max = ret_max1.pivot(index = 'PERMNO', columns = 'date', values = 'RET')\n",
    "nodiv_full_ret_max = ret_max2.pivot(index = 'PERMNO', columns = 'date', values = 'RETX')\n",
    "dlret_max = dlret_max1.pivot(index = 'PERMNO', columns = 'date', values = 'DLRET')    \n",
    "age_max =  age_max1.pivot(index = 'PERMNO', columns = 'date', values = 'Age')\n",
    "price_max = price_max1.pivot(index = 'PERMNO', columns = 'date', values = 'PRC')\n",
    "# div_max = div_max1.pivot(index='PERMNO',columns='date',values='DIVAMT')\n",
    "size_max = size_max1.pivot(index = 'PERMNO', columns = 'date', values = 'Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating ListofAvailable Dict\n",
    "\n",
    "Have a dict of lists of available stocks in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = startm\n",
    "year=  starty\n",
    "\n",
    "listofdates = []\n",
    "listofavailable = {}\n",
    "listofyears = []\n",
    "fulllistofavailable = {}\n",
    "while(year<=endy):\n",
    "    listofyears.append(year)\n",
    "    while(month <= 12):\n",
    "        curdate = year*100 + month\n",
    "        listofdates.append(curdate)\n",
    "        y = ret_max.index[(ret_max[curdate].notnull())].tolist()\n",
    "        x = full_ret_max.index[(full_ret_max[curdate].notnull())].tolist()\n",
    "        listofavailable[curdate] = y\n",
    "        fulllistofavailable[curdate] = x\n",
    "        month += 1\n",
    "    month = 1\n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalanced Portfolio Method Simulation\n",
    "\n",
    "This portfolio selected N stocks in the starting month such that each stock is of equal weight in the portfolio. After each month the stocks are rebalanced so that the equal weighting is maintained. Delisted stocks are replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_num = 100\n",
    "\n",
    "\n",
    "\n",
    "#Rebalanced Simulation\n",
    "ew_ret = {} #dictionary of monthly returns   \n",
    "exits = []\n",
    "entrants = []\n",
    "ret_list = []\n",
    "# in_list = []\n",
    "agedict = {}\n",
    "ew_ret_list = {}\n",
    "year = starty\n",
    "month = startm\n",
    "\n",
    "while(year <= endy):\n",
    "    while(month<= 12):\n",
    "        curdate=  year*100 + month\n",
    "        agedict[curdate] = []\n",
    "        month+=1\n",
    "    month = 1\n",
    "    year += 1\n",
    "    \n",
    "    \n",
    "n_list = [5,25,50,100]\n",
    "#dictionaries to keep track of variables on a month by month basis\n",
    "ret_dict = {'rebalanced':{},'bootstrapped':{}}\n",
    "turnover_dict = {'rebalanced':{},'bootstrapped':{}}\n",
    "turnover_dict_list = {'rebalanced':{},'bootstrapped':{}}\n",
    "ret_dict_list = {'rebalanced':{},'bootstrapped':{}}\n",
    "age_dict_list = {'rebalanced':{},'bootstrapped':{}}\n",
    "for strat in ret_dict:\n",
    "    for w in n_list:\n",
    "        ret_dict[strat][w] = []\n",
    "        turnover_dict[strat][w] = []\n",
    "        ret_dict_list[strat][w] = {}\n",
    "        age_dict_list[strat][w] = {}\n",
    "        size_dict_list[strat][w] = {}\n",
    "        turnover_dict_list[strat][w] = {}\n",
    "        for i in listofdates:\n",
    "            turnover_dict_list[strat][w][i] = []\n",
    "            ret_dict_list[strat][w][i] = []\n",
    "            age_dict_list[strat][w][i] = []\n",
    "            size_dict_list[strat][w][i] = []\n",
    "            age_dict_list[strat][w][i] = []\n",
    "\n",
    "strat = 'rebalanced'\n",
    "for N in n_list:\n",
    "    for j in range(0,simulation_num):\n",
    "        ew_ret = {}\n",
    "        turnover = [] #list to keep track of turnover month by month\n",
    "#         exits = []\n",
    "#         entrants = []\n",
    "#         in_list = []\n",
    "        total_ret = 1 #initalize return as zero\n",
    "        start = time.time()\n",
    "        for i in listofdates:\n",
    "            if(i == startd):\n",
    "                prev_sample = sample(listofavailable[i],N) #Take first sample\n",
    "                ew_ret[i] = sum(ret_max.loc[prev_sample,i])\n",
    "                ew_ret[i] += sum(dlret_max.loc[prev_sample,i])\n",
    "                ew_ret[i] = 1 + ew_ret[i] /N #calculate monthly return\n",
    "                ret_dict_list[strat][N][i].append(ew_ret[i])\n",
    "                age_dict_list[strat][N][i].append(mean(age_max.loc[prev_sample,i]))\n",
    "                size_dict_list[strat][N][i].append(mean(size_max.loc[prev_sample,i]))\n",
    "                turn = np.mean(np.abs(ret_max.loc[prev_sample,i].values))\n",
    "                turnover_dict_list[strat][N][i].append(turn)\n",
    "#                 turnover.append(turn)\n",
    "            else:\n",
    "                    \n",
    "                cur_sample = list(set(prev_sample)& set(listofavailable[i])) #find items in next date\n",
    "\n",
    "                diff = list(set(prev_sample) - set(cur_sample)) #find items that have exited either due to reclassification or delisting\n",
    "                reclassified = list(set(fulllistofavailable[i]) & set(diff)) #find items that have been reclassified\n",
    "\n",
    "                cur_sample = cur_sample + reclassified #add back in items that have been reclassified\n",
    "                \n",
    "                percent_prc_chg = np.abs(nodiv_full_ret_max.loc[cur_sample,i])\n",
    "\n",
    "                exitnum = N - len(cur_sample) #how many stocks have exited\n",
    "                turn = (np.mean(percent_prc_chg) * len(cur_sample) + exitnum)/N\n",
    "                turnover_dict_list[strat][N][i].append(turn)\n",
    "#                 turnover.append(turn)\n",
    "\n",
    "                filling = sample(set(listofavailable[i])-set(cur_sample), exitnum) #sample in to fill exited stocks\n",
    "\n",
    "                if(len(filling)>0):  #add new samples to portfolio\n",
    "                    cur_sample.extend(filling) \n",
    "                    \n",
    "                normal_returns = full_ret_max.loc[cur_sample,i]\n",
    "                delisting_returns = dlret_max.loc[cur_sample,i]\n",
    "\n",
    "\n",
    "                ew_ret[i] = sum(normal_returns) #get return matrix\n",
    "                ew_ret[i] += sum(delisting_returns) #get delisting returns\n",
    "                ew_ret[i] = 1 + ew_ret[i]/N #return for a given month\n",
    "                \n",
    "                ret_dict_list[strat][N][i].append(ew_ret[i]) #append to monthly return list\n",
    "                \n",
    "                averageage = mean(age_max.loc[prev_sample,i])\n",
    "                age_dict_list[strat][N][i].append(mean(age_max.loc[prev_sample,i]))\n",
    "                size_dict_list[strat][N][i].append(mean(size_max.loc[prev_sample,i]))\n",
    "                \n",
    "                prev_sample = cur_sample\n",
    "            total_ret = total_ret * ew_ret[i] #keep a running track of total return\n",
    "        end = time.time()\n",
    "    \n",
    "        annualizedret = total_ret ** (1/((len(listofdates)-1)/12)) -1\n",
    "        print(f'It took {end-start} seconds for simulation #{j} of portfolio size {N}, Ann. Ret. = {annualizedret}')\n",
    "\n",
    "        ret_dict[strat][N].append(annualizedret)\n",
    "        total_turnover = sum(turnover)/len(turnover)\n",
    "        turnover_dict[strat][N].append(total_turnover)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapped Portfolio Simulation\n",
    "\n",
    "This portfolio selects N stocks with equal weight in the first month. It then selects N new stocks every new month. Turnover is obviously very high with this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrapped Simulation\n",
    "\n",
    "simulation_num = 100\n",
    "\n",
    "boot_ret_list = []\n",
    "\n",
    "strat = 'bootstrapped'\n",
    "\n",
    "for j in range(0,simulation_num):\n",
    "    print(j)\n",
    "    total_ret = 1.00\n",
    "    for i in listofdates:\n",
    "        prev_sample = sample(listofavailable[i],N)\n",
    "        ew_ret[i] = sum(ret_max.loc[prev_sample,i])\n",
    "        ew_ret[i] += sum(dlret_max.loc[prev_sample,i])\n",
    "        ew_ret[i] = 1 + ew_ret[i] /N\n",
    "        averageage = mean(age_max.loc[prev_sample,i])\n",
    "        age_dict_list[strat][N][i].append(averageage)\n",
    "        ret_dict_list[strat][N][i].append(ew_ret[i])\n",
    "        size_dict_list[strat][N][i].append(ew_ret[i])\n",
    "        turnover_dict_list[strat][N][i].append(1)\n",
    "        total_ret = total_ret * ew_ret[i]\n",
    "        \n",
    "    annualizedret = total_ret ** (1/(len(listofdates)/12)) -1\n",
    "    ret_list[strat].append(annualizedret)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Profile of Bootstrapped vs Rebalanced Simulation\n",
    "\n",
    "It is clear that the rebalanced portfolio outperforms the bootstrapped portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "rect_list = []\n",
    "i = 0\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "for strat in ret_dict_list:\n",
    "    for size in n_list:\n",
    "        if i == 0:\n",
    "            labels.append(size)\n",
    "        print(strat)\n",
    "    #     rounded_avg_ret = [ round(elem, 2) for elem in ret_dict[size]]\n",
    "        mean_ret = mean(ret_dict[strat][size])\n",
    "        print(f'Portfolio Size: {size} - Mean Return:{mean_ret}, Median Return: {median(ret_dict[strat][size])} Skew Return:{skew(ret_dict[strat][size])},Mean Turnover: {mean(turnover_dict[strat][size])},Skew Turnover: {skew(turnover_dict[strat][size])}')\n",
    "        rect_list.append(ax.bar(x-width/len(n_list),mean_ret,width,label=strat)\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Mean Annualized Return')\n",
    "ax.set_title('Return Comparison by Portfolio Size')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "for r in rect_list:\n",
    "    autolabel(r)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age, Size, and Monthly Return Through Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in n_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turnover Through Time\n",
    "\n",
    "We can see that in periods of volatility, such as 2008 and the late 1990's turnover spikes. As stocks move around more more wealth from the rebalanced portfolios must be sacrificed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from statistics import median    \n",
    "    \n",
    "\n",
    "avg_dict_ret = {}\n",
    "avg_dict_turn = {}\n",
    "for i in listofdates:\n",
    "    avg_dict_ret[i] = sum(ret_dict_list[100][i])/len(ret_dict_list[100][i])\n",
    "    avg_dict_turn[i] = sum(turnover_dict_list[100][i])/len(turnover_dict_list[100][i])\n",
    "\n",
    "    \n",
    "\n",
    "dates = list(avg_dict_turn.keys())           # list() needed for python 3.x\n",
    "for l in range(0,len(dates)):\n",
    "    date = datetime.strptime(str(dates[l]), '%Y%m').date()\n",
    "    dates[l] = date\n",
    "AVG_turnover = list(avg_dict_turn.values())        # ditto\n",
    "rounded_avg_turnover = [ round(elem, 2) for elem in AVG_turnover]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#set locator to every decade\n",
    "locator = mdates.YearLocator(10)\n",
    "\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "\n",
    "\n",
    "\n",
    "ax.format_xdata = mdates.DateFormatter('%Y-%m')\n",
    "ax.grid(True)\n",
    "\n",
    "# rotates and right aligns the x labels, and moves the bottom of the\n",
    "# axes up to make room for them\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "\n",
    "ax.plot_date(dates, AVG_turnover, '-')\n",
    "\n",
    "\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "# fig.suptitle('Turnover Through Time', fontsize=20)\n",
    "ax.tick_params(axis=\"x\", labelsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "fig.suptitle('Rebalanced Portfolio Overtime')\n",
    "\n",
    "# fig.savefig('turnover.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turnover vs annualized return for rebalanced portfolios\n",
    "\n",
    "There does not appear to be a relationship between increased turnover and increased annualized return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = np.asarray(ret_dict[100])\n",
    "y = np.asarray(turnover_dict[100])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y)\n",
    "\n",
    "ax.set_xlabel('Annualized Return', fontsize = 20)\n",
    "ax.set_ylabel('Turnover', fontsize = 20)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=20)\n",
    "ax.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "# fig.savefig('scatter.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
